\documentclass{article}

% Command + Option + V to view the PDF in VSCode

% Trevor's ShorTeX
\usepackage{shortex}

% Page setup
\usepackage[left=2.5cm, right=2.5cm, top=2.5cm, bottom=2.5cm]{geometry}
\setlength{\parindent}{0pt} % No indent at the beginning of paragraphs
\setlength{\parskip}{7pt}  % Gap between paragraphs

% Choose between bibliography and references
% \renewcommand{\refname}{Bibliography}
\renewcommand{\refname}{References}


\begin{document}

\begin{center}
    \huge{\underline{Qualifying Paper 2} \\
        \vspace{5pt}
        Metropolis Adjusted Microcanonical \\
        \vspace{5pt}
        Hamiltonian Monte Carlo}

    \vspace{1cm}

    \Large{Professor: Trevor Campbell}

    \vspace{1cm}

    \Large{Isaac Rankin}

    \vspace{1cm}

    \large \today
\end{center}

\newpage



% Table of Contents
\tableofcontents
\newpage



% The first section of the report should provide a critical analysis (max 5 pages) of the paper. 
% It should summarize the problem the paper addresses in the context of previous work, 
% limitations of previous work, the solution technique, important results, why they are important, 
% and limitations of the paper. 
% Papers listed below may have multiple contribution areas (theory, modelling, computation), 
% and the summary should reflect that. 
% The goal of this portion of the report is to show that you can take a complex body of work
% (one paper and earlier relevant work), digest it, 
% and present a concise summary of the important points, and comment on them. 



\section{Introduction}

Suppose we wish to draw samples from a possibly unnormalised density $p: \reals^d \to \reals$.
Markov chain Monte Carlo (MCMC) algorithms construct a sequence $\{ \skx_i \}_{i = 1}^n$ where each $\skx_i \in \reals^d$ \cite{neal2011mcmc}.
When the MCMC algorithm is designed carefully, the empirical distribution of the sequence, or chain, approximates $p$.
In many applications, practitioners desire \cite{robnik2023microcanonical, robnik2025metropolis} that asymptotically,
the distribution of chain converges to $p$, ensuring that the samples can be used to make unbiased inferences.

When gradient information is available, gradient-based MCMC methods can achieve substantially better efficiency than random-walk methods,
particularly in high dimensions \cite{neal2011mcmc, betancourt2017conceptual}.
For interdisciplinary applications, automatic hyperparameter tuning schemes are highly desirable,
as they allow practitioners to obtain samples without requiring expertise in the algorithm's implementation.
Such automatically tuned algorithms are often referred to as \textit{blackbox}.

Robnik, Cohn-Gordon, and Seljak (RCS) propose the Metropolis-adjusted microcanonical sampler (MAMS) \cite{robnik2025metropolis},
which adds a Metropolis-Hastings correction to the earlier asymptotically biased microcanonical Hamiltonian Monte Carlo (MCHMC)
and its variant, microcanonical Langevin-like Hamiltonian Monte Carlo (MCLMC).
The primary contribution is deriving the correct acceptance probability for dynamics whose numerical integrator is not volume-preserving.

This report critically examines the manuscript
\textit{Metropolis Adjusted Microcanonical Hamiltonian Monte Carlo} \cite{robnik2025metropolis} which introduced MAMS.
We analyze the technical details, discuss the contributions of the work,
and identify limitations and unanswered questions regarding the novel algorithm.
We supplement this analysis with a project comparing RCS's hyperparameter tuning scheme to a Bayesian optimization approach.







\section{Hamiltonian Monte Carlo and related work}

We shall now briefly introduce Hamiltonian Monte Carlo (HMC) and discuss work related to that of RCS.

We write the target density as $p(\skx) = e^{-\scL(\skx)}/Z$ where $Z = \int e^{-\scL(\skx)} d\skx$ is the normalizing constant, and $\scL(\skx) = -\log p(\skx) - \log Z$.
Note that gradients of $p$ are proportional to those of $\scL$: $\grad \scL(\skx) = -\grad p(\skx) / p(\skx) \propto \grad p(\skx)$.

HMC augments the target `position' $\skx$ with an ancillary `momentum' $\sku \in \reals^d$, forming a so-called `phase-space' \cite{neal2011mcmc, betancourt2017conceptual}.
Following RCS's nomenclature, we refer to the standard HMC dynamics as the `canonical' Hamiltonian dynamics: $\sokx = \sku, \; \soku = -\grad \scL(\skx)$,
where $\sokx$ and $\soku$ are the time derivatives of the position and momentum respectively.
A solution to this system of differential equations corresponds to trajectories on level sets of the separable Hamiltonian $H(\skx, \sku) = \scL(\skx) + \frac{1}{2}\sku^T \sku$.
Typically, we write $H(\skx, \sku) = V(\skx) + K(\sku)$, where the potential energy is $V(\skx) = \scL(\skx)$, and the kinetic energy is $K(\sku) = \frac{1}{2}\sku^T \sku$ \cite{neal2011mcmc}.
The stationary distribution describing $(\skx, \sku)$ on phase-space is $p(\skx) \; \Norm(\sku; \s[k]0, \s[k]I)$ \cite{neal2011mcmc, betancourt2017conceptual}.
Crucially, the numerical integrator for canonical HMC, typically the leapfrog (Verlet) integrator, is symplectic \cite{neal2011mcmc, robnik2025metropolis, betancourt2017conceptual}, that is,
it preserves phase-space volume and so its corresponding Jacobian determinant is one, simplifying the Metropolis-Hastings acceptance probability calculation.

Robnik and Seljak, collaborating with Bruno De Luca and Silverstein, previously introduced
microcanonical Hamiltonian Monte Carlo (MCHMC) and microcanonical Langevin-like Hamiltonian Monte Carlo (MCLMC) \cite{robnik2023microcanonical},
which simulate `microcanonical dynamics' with unit-norm momentum $\| \sku \| = 1$.
The microcanonical dynamics are defined as:
\[
    \sokx = \sku, \qquad \soku = -\frac{I - \sku\sku^T}{d-1} \grad \scL(\skx).
\]
The projection operator $(I - \sku\sku^T)/(d-1)$ ensures $\s[ok]u \perp \sku$, preserving $\| \sku \| = 1$
and constraining the momentum to the unit sphere $S^{d-1}$ \cite{robnik2023microcanonical, robnik2025metropolis, robnik2023fluctuation, robnik2024black}.
When integrated exactly, these dynamics have stationary distribution $p(\skx) \; \scU_{S^{d-1}}(\sku)$ \cite{robnik2023microcanonical}.
In contrast to canonical HMC, the leapfrog integrator for microcanonical dynamics is not symplectic \cite{robnik2023microcanonical,robnik2025metropolis,betancourt2017conceptual}.
The projection operator compresses or expands the phase-space volume depending on alignment between momentum and gradient.
This means the Jacobian determinant is not one, and computing the acceptance probability requires additional work.
The prior work on MCHMC and MCLMC avoided this issue by not including a Metropolis-Hastings step, accepting the resulting asymptotic bias \cite{robnik2023microcanonical, robnik2025metropolis, robnik2023fluctuation, robnik2024black}.
Note that the algorithms MCHMC and MCLMC differ by momentum resampling.
MCHMC samples a unit-norm momentum vector every $k \in \nats$ trajectories whereas MCLMC pertubes the momentum frequently during the trajectory \cite{robnik2023microcanonical, robnik2023fluctuation}.
Either MCHMC and MCLMC can be augmented with a Metropolis accept-reject step to ensure asymptotic unbiasedness \cite{robnik2025metropolis}.
From here on, we refer to MAMS as the Metropolis-adjusted MCHMC with $k = 1$.

For both the canonical and microcanonical dynamics, $p(\skx) = \int p(\skx) \; \Norm(\sku; \s[k]0, \s[k]I) d\sku = \int p(\skx) \; \scU_{S^{d-1}}(\sku) d\sku$ and so sampling from $p$
is equivalent to simulating the dynamics to obtain a position-momentum pair $(\skx, \sku)$ and discarding the momentum $\sku$.
As solving this system exactly is typically intractable, we use numerical integrators whose discretisation error requires a Metropolis-Hastings correction to ensure the
sampler targets the joint distribution of $(\skx, \sku)$ exactly \cite{neal2011mcmc, betancourt2017conceptual}.
Note that RCS call on terminology from statistical physics, calling their method `microcanonical' because the momentum magnitude is fixed,
analogous to fixed energy in NVE (microcanonical) ensembles, rather than varying energy as for NVT (canonical) ensembles \cite{robnik2023microcanonical, robnik2025metropolis, tong2009university}

Several previous HMC variants have modified either the dynamics, or the mass structure (and hence the momentum).
Note that by setting the `mass' of the fictitious particle equal to one, we can use the terms `momentum' and `velocity' interchangeably.
Riemannian manifold HMC \cite{girolami2011riemann} uses a position-dependent mass matrix $M(\skx)$ with kinetic energy $K(\skx, \sku) = \frac{1}{2}\sku^T M(\skx)^{-1} \sku$, adapting to local curvature.
Relativistic HMC \cite{lu2017relativistic} uses $K(\sku) = \sqrt{1 + \| \sku \|^2}$ (with additional hyperparameters set to 1 here), bounding velocity for stability to large gradients.
Magnetic HMC \cite{tripuraneni2017magnetic} introduces non-canonical dynamics, has an accept-reject step, but crucially the integrator for these dynamics is volume preserving.
Magnetic HMC follows the dynamics $\s[ok]x = F\sku + E \grad U(\skx) \; \s[ok]u = F^T \grad U(\skx) + G \sku$ where $F, E, \text{and} G$ form an antisymmetric block matrix,
generalizing the canonical dynamics which can be written in matrix notation with the positive and negative identity matrix on the diagonal, and the zero matrix on the off diagonal.
Pakman \cite{pakman2025super} explore non-standard dynamics, sampling momentum from the Laplace distribution yeilding a Hamiltonian (choosing constants equal to 1) $H(\skx, \sku) = - \cos(\skx) + |\sku|$.
Ver Steeg and Galstyan chose a `kinetic' energy $K(\sku) = \frac{d}{2} \log \| \frac{\sku}{d} \|$ \cite{ver2021hamiltonian}.
They argued that in machine learning applications, enforcing physicallity is irrelevant \cite{ver2021hamiltonian}, justifying their `non-Newtonian' momentum.
The microcanonical dynamics used by RCS are equivalent to those employed by Ver Steeg and Galstyan, though doubts have been raised as to whether
their deterministic algorithm produces an ergodic chain \cite{robnik2023microcanonical, robnik2025metropolis}.


There have also been advancements in hyperparamater tuning schemes.
Proposals are generated by numerically integrating the chosen dynamics, often using the leapfrog or Verlet integrator \cite{neal2011mcmc, betancourt2017conceptual}.
The leapfrog integrator approximating the dynamics, requires tuning of step size $\epsilon$ and trajectory length $L$.
In order to make an algorithm blackbox, $\epsilon$ and $L$, and in some cases a preconditioner matrix to make variability comparable across dimensions \cite{hird2025quantifying},
must be selected without input from the practitioner.
Too large of step sizes can cause instability and low acceptance rates; small step sizes waste computation through small moves causing slow exploration \cite{campbell2021gradient}.
Trajectory lengths must balance exploration with efficiency to avoid retracing paths \cite{hoffman2014no}.
The No-U-Turn sampler (NUTS) \cite{hoffman2014no} automates trajectory length selection by growing trajectories until they double back, eliminating manual tuning of $L$.
Step size adaptation during warmup uses dual averaging \cite{hoffman2014no, nesterov2009primal} based on acceptance rate tracking.
There are many strategies for tuning hyperparameters.
This problem will be the focus of the project in Section 7.





\section{Deriving the acceptance probability}

MAMS adds a Metropolis-Hastings acceptance step to MCHMC to eliminate asymptotic bias.
The primary technical challenge--and main contribution of RCS--is deriving the correct acceptance probability for dynamics whose numerical integrator is not volume-preserving.
For canonical HMC, the symplectic integrator ensures the Jacobian determinant equals one \cite{neal2011mcmc}, simplifying the acceptance probability to a potential energy difference.
For microcanonical dynamics, this simplification does not hold.

The microcanonical dynamics are approximated using leapfrog integration with step size $\epsilon$ and trajectory length $L$, yielding $n = \lceil L/\epsilon \rceil$ steps.
The leapfrog integrator is the composition:
\[
    \rho = \scT \circ (B_{\epsilon/2} \circ A_\epsilon \circ B_{\epsilon/2}) \circ \cdots \circ (B_{\epsilon/2} \circ A_\epsilon \circ B_{\epsilon/2})
\]
where
\[
    B_{\epsilon/2}: & \quad \sku \leftarrow \sku - \frac{\epsilon}{2} \frac{I - \sku \sku^T}{d-1} \grad \scL(\skx), \\
    A_\epsilon:     & \quad \skx \leftarrow \skx + \epsilon \sku
\]
and $(B_{\epsilon/2} \circ A_\epsilon \circ B_{\epsilon/2})$ is composed $n$ times.
After $n$ steps, momentum is flipped: $\scT(\skx, \sku) = (\skx, -\sku)$.
The integrator $\rho$ is reversible, that is, an involution $\rho \circ \rho = id$, where $id$ denotes the identity $id(\skx) = \skx$ for every $\skx \in \reals^d$.
Crucially, unlike canonical HMC, the leapfrog integrator for microcanonical dynamics is \textit{not volume-preserving}, necessitating computing a determinant of a Jacobian.

For a proposal $\skz' = (\skx', \sku')$ from current state $\skz = (\skx, \sku)$, the required acceptance probability \cite{neal2011mcmc} is:
\[
    \min \left( 1, \frac{p(\skz')}{p(\skz)} \frac{q(\skz | \skz')}{q(\skz' | \skz)} \right) = \min \left( 1, e^{-W(\skz', \skz)} \right).
\]
Since $\sku$ and $\sku'$ are both uniformly distributed on $S^{d-1}$, we have $\scU_{S^{d-1}}(\sku) = \scU_{S^{d-1}}(\sku')$, and so the density ratio becomes:
\[
    \frac{p(\skz')}{p(\skz)} = \frac{p(\skx') \; \scU_{S^{d-1}}(\sku')}{p(\skx) \; \scU_{S^{d-1}}(\sku)} = \frac{p(\skx')}{p(\skx)} = e^{-(\scL(\skx') - \scL(\skx))}.
\]
The proposal density ratio requires more careful treatment as $\rho$ is not volumne preserving.
As $\rho$ is deterministic and reversible, $q(\skz' | \skz) = \delta(\skz' - \rho(\skz))$ and $q(\skz | \skz') = \delta(\skz - \rho(\skz'))$ where $\delta(\cdot)$ is the Dirac delta function.
Using a change of variables:
\[
    \delta(\skz - \rho(\skz')) = \delta(\skz' - \rho(\skz)) \left|\frac{\partial \rho}{\partial \skz}(\skz)\right|
\]
therefore:
\[
    \frac{q(\skz | \skz')}{q(\skz' | \skz)} = \frac{\delta(\skz - \rho(\skz'))}{\delta(\skz' - \rho(\skz))} = \left|\frac{\partial \rho}{\partial \skz}(\skz)\right|.
\]
Applying Liouville's theorem to the microcanonical dynamics written as vector field $\dot{\skz}(t) = F(\skz(t)) = (\sku(s), -\frac{I - \sku(s)\sku(s)^T}{d-1} \grad \scL(\skx(s)))$ for which $\rho$ approximates, he have:
\[
    \log\left|\frac{\partial \rho}{\partial \skz}(\skz)\right| \approx \int_0^L \grad \cdot F(\skz(s)) \, ds
\]
where equality would be achieved if $\rho$ solves the dynamics exactly.
But this divergence can be computed as follows:
\[
    \grad \cdot F(\skz(s))
    &= \grad_{\skx} \cdot (\sku) + \grad_{\sku} \cdot (-\frac{I - \sku\sku^T}{d-1} \grad \scL(\skx)) \\
    &= 0 - \frac{1}{d-1}\grad_{\sku} \cdot \left( (I - \sku \sku^T) \grad \scL(\skx) \right) \\
    &= -\frac{1}{d-1}\sku^T \grad \scL(\skx).
\]
$W(\skz', \skz)$ from the acceptance probability $\min(1, e^{-W(\skz', \skz)})$ is therefore:
\[
    W(\skz', \skz) = \scL(\skx') - \scL(\skx) + \int_0^L \frac{1}{d-1} \sku(s)^T \grad \scL(\skx(s)) \, ds
\]
this integral is zero for the canonical case as $\rho$ is simpletic but accounts for volume compression or expansion in the microcanonical case.
$\sku(s)^T \grad \scL(\skx(s))$ measures the alignment between the log-density and the momentum.

As $\rho$ approximates these dynamics using discrete steps, we can calculate \cite{robnik2025metropolis} $W(\rho(\skz), \skz)$ as: \\
$W(\rho(\skz), \skz) = \sum_{k=1}^n \left[ V(A_{\epsilon_k}(\skz_{k-1})) - V(\skz_{k-1}) + K(B_{\epsilon_k} \circ A_{\epsilon_k}(\skz_{k-1})) - K(A_{\epsilon_k}(\skz_{k-1})) \right]$.

The potential energy change is the same as for canonical HMC: $V(A_\epsilon(\skz)) - V(\skz) = - \log \frac{p(\skx')}{p(\skx)}$.
For canonical HMC with step size $\epsilon$, the kinetic energy change is: $K(B_\epsilon(\skz)) - K(\skz) = \frac{1}{2}\|\sku'\|^2 - \frac{1}{2}\|\sku\|^2$.
For MAMS: $K(B_\epsilon(\skz)) - K(\skz) = (d-1) \log(\cosh \delta + \ske \cdot \sku \sinh \delta)$ where $\ske = -\grad \scL(\skx) / \|\grad \scL(\skx) \|$ and $\delta = \epsilon \|\grad \scL(\skx)\| / (d-1)$.
Which was found by solving a nonlinear first order differential equation \cite{robnik2023microcanonical, robnik2025metropolis, ver2021hamiltonian}.
So, for both HMC and MAMS, the Metropolis-Hastings acceptance probability can be computed by tracking the total energy change $W$ along the discretized trajectory.
The crucial difference is that MAMS requires the volume correction term from the divergence of the velocity update, while HMC using canonical dynamics does not.
The derivation is mathematically sound and resolves the limitation that prior microcanonical samplers (MCHMC, MCLMC) were asymptotically biased.





\section{Behaviour of microcanonical dynamics}

A key property of microcanonical dynamics emphasized by RCS is stability to large gradients.
To understand this property, consider the behavior of particles under both systems of differential equations along a trajectory without momentum resampling.

The canonical dynamics $\sokx = \sku, \soku = -\grad\scL(\skx)$ leave momentum magnitude $\| \sku \|$ unconstrained and varying according to the gradient.
When $\| \grad\scL(\skx) \|$ is large, the update $\sku_{k+1} = \sku_k - \epsilon\grad\scL(\skx_k)$ can produce $\| \sku_{k+1} \| \gg \| \sku_k \|$,
leading to very large position steps $\skx_{k+2} = \skx_{k+1} + \epsilon\sku_{k+1}$.
This potentially causes rejection of the proposed state or numerical instability.

The microcanonical dynamics $\sokx = \sku, \soku = -\frac{I - \sku\sku^T}{d-1}\grad\scL(\skx)$ enforce the constraint $\| \sku \| = 1$, implying $\| \sokx \| = \| \sku \| = 1$ always.
The projection operator ensures $\soku \perp \sku$, so momentum changes alter the direction, but not magnitude of $\sku$.
Even when $\|\grad\scL(\skx) \|$ is large, the speed remains constant.
Large gradients cannot cause unbounded momentum growth.

The momentum restriction has implications for the characteristics of the particle’s phase-space exploration.

For canonical dynamics, energy conservation in the Hamiltonian $H(\skx, \sku) = V(\skx) + K(\sku)$ creates an inverse relationship between kinetic and potential energy.
In high-probability regions, $p(\skx)$ is high and thus $\scL(\skx) = -\log p(\skx)$ is low.
Potential energy is low and so kinetic energy must be correspondingly high.
Particles move rapidly through high-density regions.
Conversely, in low-probability regions with high potential energy, kinetic energy is low and particles may struggle to traverse these areas.

For microcanonical dynamics, the momentum magnitude is independent of the density at any point, ensuring a consistent speed of exploration through all regions.
In steep regions, the particle's direction changes sharply due to the projection operator but speed remains constant.
The Metropolis step can reject proposals to lower-density regions, preventing excessive exploration there.
A potential issue arises when a ridge divides a flat region between two modes.
Upon encountering such a ridge, the particle's momentum rotates but may fail to traverse the ridge,
possibly causing the particle to fail to explore the full space.






\section{Limitations}

MAMS represents a technically correct algorithmic development that extends MCHMC and MCLMC with a Metropolis-Hastings correction,
eliminating asymptotic bias through derivation of the acceptance probability for non-volume-preserving microcanonical dynamics.
However, substantial theoretical and empirical gaps remain.

MAMS lacks convergence rate bounds for classes of target densities.
For instance, canonical HMC has mixing time bounds for strongly log-concave targets \cite{chen2019optimal} but no analogous results exist for MAMS.
Without such an analysis, it is unclear when MAMS is guaranteed to converge faster than canonical methods and how performance scales with the dimension of the problem.

The paper provides no characterization of when the unit-norm constraint helps versus hinders exploration,
nor diagnostic tools for MAMS-specific failure modes such as when volume corrections dominate acceptance decisions.
It remains unclear for which target geometries favour microcanonical dynamics.
In addition, MAMS exceeds standard HMC leapfrog implementation complexity as it requires computing the volume change.

In the case $d = 1$, the constraint that $\| \sku \| = 1$ reduces to $\sku \in \{-1, 1\}$.
The projection operator $\frac{I - \sku\sku^T}{d-1}$ becomes undefined due to division by $d-1 = 0$.
Regardless, in one dimension $I - \sku\sku^T = 0$, so the momentum never changes.
Ver Steeg and Galstyan \cite{ver2021hamiltonian} noted this but dismissed it as the issue does not occur for higher dimensions.

The term `Hamiltonian Monte Carlo' refers to methods based on Hamiltonian mechanics with volume-preserving dynamics \cite{neal2011mcmc, betancourt2017conceptual}.
MAMS does not employ true Hamiltonian dynamics as noted by RCS \cite{robnik2025metropolis}.
RCS also note that the 'kinetic energy' for microcanonical dynamics is not in the standard sense.
Drawing parallels to Hamiltonian dynamics and kinetic energy can confuse readers and practitioners.

The manuscript suffers from several presentation issues that detract from its technical contributions.
Notation is inconsistent, with variables appearing in both script and non-script forms.
The reference list contains duplicate entries with varying capitalization.
More concerning is the self-citation.
The manuscript exists as two arXiv versions (v1 from March 2025, v2 from May 2025, both arXiv:2503.01707), yet version 2 cites version 1.




\section{Conclusion}

The Metropolis-adjusted microcanonical sampler makes a technical contribution by deriving the acceptance probability for non-volume-preserving microcanonical dynamics,
correcting the asymptotic bias present in MCHMC and MCLMC.
The derivation is mathematically correct and demonstrates that Metropolis correction can be applied to dynamics whose integrators do not preserve phase-space volume.
The unit-norm momentum constraint provides stability to large gradients, a property that may be of benefit in some cases.

A theoretical analysis of when and why microcanonical dynamics outperform canonical dynamics would be beneficial for this new methodology to gain trust and support.
Additionally, presentation issues and misleading nomenclature reduce the work's accessibility.






% The remainder of the report (no page limit) will be devoted to a small paper-specific project that
% we decide on together (come to our first meeting with ideas). 
% Your grade will not be affected by how good the results look, whether your approach improves on past work, 
% or whether you achieve the initial goal of the project. 
% The aim of this exercise, from my perspective, is to evaluate your research potential. 
% This includes taking a problem and formulating it precisely, whiteboarding some ideas with me and on your own, 
% thinking creatively and independently to develop a solution, asking questions when necessary, selecting
% ways to investigate / justify claims, choosing appropriate metrics, reflecting on and communicating results,
% choosing the next course of action / reformulating the problem when things don’t turn out well, thinking of
% future directions, etc. 

\newpage
\section{Project: Comparison of MAMS Hyperparameter Tuning Schemes}

\subsection{Introduction}


The Metropolis-adjusted microcanonical sampler (MAMS) algorithm requires careful tuning of two key hyperparameters:
the trajectory length $L$, and the step size $\epsilon$.
While it is also possible to tune a preconditioner matrix, we simplify our analysis by setting it equal to the identity matrix.
We focus on the MCHMC variant of MAMS, which samples a new unit-norm momentum vector between trajectories,
but does not partially refresh the momentum within the trajectory, as would be done in the MCLMC variant.

The approach to tuning MAMS proposed by RCS \cite{robnik2025metropolis} is a sequential optimization that tunes hyperparameters one at a time across three distinct phases,
each of length $0.1N$ samples where $N$ is the desired chain length.
However, this sequential approach has a fundamental limitation: it cannot capture interactions between $L$ and $\epsilon$
as each parameter is optimized while holding the other fixed.
When $\epsilon$ is optimized with $L$ held constant, then $L$ is optimized with $\epsilon$ fixed,
the resulting configuration may represent only a local optima.

We hypothesize that jointly exploring the $(L, \epsilon)$ space using Bayesian optimization (BayesOpt)
will yield hyperparameter pairs closer to the global optimum.
Instead of fixing one parameter while tuning the other, BayesOpt proposes candidate pairs from the hyperparameter space,
evaluates their performance, updates its acquisition function based on the result, and iterates.
After a chosen number of iterations, the hyperparameters which maximized a carefully chosen objective function are selected and used in all further chains.

For every chain, sequential tuning requires and discards an additional 20\% of the desired chain length (or 30\% when also tuning the preconditioner matrix)
for the chain's idependent hyperparameter adaptation.
If there is variability between hyperparamaters found for each chain, this suggests that the RCS tuning method converged to local optima.
In contrast, BayesOpt invests heavily in an initial search phase but then reuses the optimal $(L^*, \epsilon^*)$ pair for all subsequent chains,
effectively amortizing the initial computational cost.
While this method may be more computationally expensive for small sampling projects,
for large projects, the investment to find a potentially superior configuration without discarding a tuning phase for each chain may be beneficial.
BayesOpt produces a single set of hyperparameters for all future chains, whereas auto-tuning produces different hyperparamater for each chain.
BayesOpt explores the $(L, \epsilon)$ space jointly, capturing potential interactions that sequential tuning cannot detect.
Our hypothesis is that joint optimization of $(L, \epsilon)$ through BayesOpt should discover better configurations with more consistent behaviour across chains.

We evaluate both methods on three target densities: the banana distribution, a correlated Gaussian, and an equal mixture of two Gaussians.
The correlated Gaussian and bimodal Gaussian are specifically constructed to have equal marginal variance, so diagonal preconditioning ought to be ineffective.
We implement MAMS using the BlackJAX \cite{cabezas2024blackjax} library in JAX \cite{bradbury2021jax}.
While the implementation of MAMS appears correct, it was necessary to modify the adaptation function to enable fixing $L$
during the dual averaging adaptation of $\epsilon$, as this functionality was not accessible by default.
The adaptation function had to be duplicated and modified to allow the sequential tuning protocol described by RCS.

The code to reproduce the experiments is available on GitHub:\\
\href{https://github.com/1saacRankin/QP2-microcanonical-HMC}{https://github.com/1saacRankin/QP2-microcanonical-HMC}.



\subsection{Sequential Auto-Tuning Method}

The sequential tuning approach, as described by RCS in their manuscript \cite{robnik2025metropolis}, adapts hyperparameters across three stages.
The algorithm is initialized with $L = \sqrt{d}$ where $d$ is the dimension of the target density,
and sets the inverse mass matrix to the identity matrix $\skM^{-1} = \skI$.
In Stage 1, which runs for $0.10N$ steps, dual averaging tunes $\epsilon$ to target a 90\% acceptance rate while holding $L$ fixed.
Stage 2, also running for $0.10N$ steps, estimates a diagonal preconditioning matrix (though we skipped this stage in our experiments).
Stage 3 refines $L$ based on autocorrelation time estimates while holding $\epsilon$ fixed, again for $0.10N$ steps.

After these tuning phases, the algorithm runs a chain of length $N$ using the tuned $(L, \epsilon)$ pair.
A critical feature of this approach is that each chain runs this tuning procedure independently, producing its own hyperparameters.
This means that chains may converge to different $(L, \epsilon)$ pairs,
which could indicate either a broad range of hyperparamters are effective, or that there is instability in the tuning procedure.

Note: as the chain automatically produces hyperparameters for itself, from the word automatically and the Greek prefix for self,
we shall refer to this tuning method as `Auto-tuning'.


\subsection{Bayesian Optimization Method}

Our BayesOpt approach jointly optimizes $(L, \epsilon)$ by modeling sampler performance as a function of both hyperparameters simultaneously.
We use a Gaussian process (GP) with a radial basis function (RBF) kernel as our surrogate model,
and use the upper confidence bound (UCB) acquisition function to balance exploration and exploitation.
The search proceeds by iteratively proposing hyperparameter pairs, evaluating their performance across multiple chains,
and updating the GP model based on the observed results.

\begin{algorithm}
    \caption{Bayesian Optimization for MAMS}
    \begin{algorithmic}%[1]
        \State \textbf{Input:} Target density, iterations $T = 20$, chains per evaluation $C = 5$, chain length $N_{\text{tune}} = 1000$
        \State Initialize search space: $L \in [0.5, 40.0]$, $\epsilon \in [0.01, 4.0]$
        \State Initialize Gaussian process with RBF kernel
        \For{$t = 1$ to $T$}
        \State Select $(L_t, \epsilon_t)$ by maximizing $\text{UCB}(L, \epsilon) = \mu(L, \epsilon) + 2 \cdot \sigma(L, \epsilon)$
        \State Run $C$ independent chains of length $N_{\text{tune}}$ with hyperparameters $(L_t, \epsilon_t)$
        \State Compute minimum ESS across dimensions for each chain, then average over the $C$ chains
        \State Compute maximum $\hat{R}$ across dimensions for each chain, then average over the $C$ chains
        \State Compute mean acceptance rate $\alpha$ for each chain, then average over the $C$ chains
        \State Evaluate objective: $f_t(L_t, \epsilon_t) = \text{ESS}(L, \epsilon) - P_{\hat{R}}(L_t, \epsilon_t) - P_{\alpha}(L_t, \epsilon_t)$
        \State Update GP with observation $(L_t, \epsilon_t, f_t)$
        \EndFor
        \State \textbf{Return:} Hyperparameters $(L^*, \epsilon^*) = (L_t, \epsilon_t)$ where $t = \argmax_{t} f_t$
    \end{algorithmic}
\end{algorithm}


The objective function aims to maximize effective sample size (ESS) while heavily penalizing configurations
that lead to non-convergent chains or artificially inflated ESS due to extremely low acceptance rates:
\[
    f(L, \epsilon) = \text{ESS}(L, \epsilon) - P_{\hat{R}}(L, \epsilon) - P_{\alpha}(L, \epsilon).
\]
The convergence penalty $P_{\hat{R}}$ ensures that we only trust ESS estimates from chains that have actually converged according to $\hat{R}$ \cite{gelman1992inference}:
\[
    P_{\hat{R}}(L, \epsilon) = C^2 \cdot N_{\text{tune}} \cdot \max(\hat{R}(L, \epsilon) - 1.0, 0).
\]
The acceptance penalty $P_{\alpha}$ prevents high ESS values that can arise when acceptance rates are extremely low.
When the sampler rarely moves, the samples can have low autocorrelation, and so high ESS.
To avoid this illusion of good performance, we linearly decrease the acceptance penalty as acceptance rates increase from 0 to 0.25:
\[
    P_{\alpha}(L, \epsilon) =
    \begin{cases}
        C^2 \cdot N_{\text{tune}} \cdot (0.25 - \alpha(L, \epsilon)) & \text{if } \alpha < 0.25 \\
        0                                                            & \text{otherwise}
    \end{cases}
\]
After 20 iterations, each using 5 chains of length 1000, that is, 100000 samples, we select the hyperparameters that achieved the highest objective value.
These optimal hyperparameters $(L^*, \epsilon^*)$ are then used for all subsequent validation chains.


\subsection{Validation Protocol}

We validate both methods using 10 independent chains of length 5000, each initialized from a different random location.
For BayesOpt, all chains use the single hyperparameter pair $(L^*, \epsilon^*)$ identified during the tuning phase.
For sequential auto-tuning, each chain independently discovers its own pair $(L^*_i, \epsilon^*_i)$ for $i = 1, 2, \ldots, 10$,
following the adaptation protocol described before.

We compare the methods across several key metrics.
The minimum effective sample size across all dimensions measures sampling efficiency \cite{vehtari2021rank}.
The maximum $\hat{R}$ across dimensions assesses convergence, with values near 1.0 indicating more likely convergence.
We also track the mean acceptance rate and wall-clock time per chain.
For the 10 validation chains, we present $\hat{R}$, and the mean and standard deviation of ESS, acceptance rate, and time per chain.
For Auto-tuned chains, we additionally examine the variability in the $L$ and $\epsilon$ values
across chains to assess the consistency of the tuning procedure.


\subsection{Bimodal Isotropic Gaussian}

The bimodal isotropic Gaussian target consists of two separated modes with equal weight and identity covariance matrices.
The density is defined as an equal mixture:
\[
    p(\skx) = \frac{1}{2} \Norm(\skx | \s[k]\mu_1, \skI) + \frac{1}{2} \Norm(\skx | \s[k]\mu_2, \skI)
\]
where $\s[k]\mu_1 = [-2, -2, \ldots, -2]^T$ and $\s[k]\mu_2 = [2, 2, \ldots, 2]^T$ in $d = 10$ dimensions.
The log density is proportional to:
\[
    \log p(\skx) \propto -\frac{1}{2}\| \skx - \s[k]\mu_1 \|^2 -\frac{1}{2}\| \skx - \s[k]\mu_2 \|^2
\]

This target tests the sampler's ability to switch between modes and properly explore both regions of high probability.
All dimensions have symmetric structure and are independent within each mode, so diagonal preconditioning offers no advantage over an identity matrix.
The challenge of this target density is achieving adequate mixing between the two modes.

\begin{table}[h]
    \centering
    \caption{Performance comparison on Bimodal Gaussian ($d=10$)}
    \begin{tabular}{lcccccc}
        \hline
        Method      & $\hat{R}$ & ESS              & Acceptance Rate   & Time/chain (s)    & $L$               & $\epsilon$        \\
        \hline
        BayesOpt    & 2.300     & 61023 $\pm$ 778  & 0.964 $\pm$ 0.001 & 0.742 $\pm$ 0.167 & 14.901            & 2.242             \\
        Auto-tuning & 2.189     & 61091 $\pm$ 1129 & 0.988 $\pm$ 0.003 & 2.908 $\pm$ 0.693 & 1.310 $\pm$ 0.119 & 1.191 $\pm$ 0.108 \\
        \hline
    \end{tabular}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{../code/plots/traces_Bimodal Gaussian.png}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{../code/plots/bayesopt_progress_Bimodal Gaussian.png}
\end{figure}





\subsection{Correlated Gaussian}

The correlated Gaussian target is a centered at the origin with a specific correlation structure:
\[
    p(\skx) = \Norm(\skx | \s[k]0, \s[k]\Sigma)
\]
where the covariance matrix has constant correlation $\rho = 0.8$:
\[
    \s[k]\Sigma = (1-\rho)\skI + \rho\s[k]1\s[k]1^T
\]

This covariance matrix has ones on the diagonal and $\rho = 0.8$ in all off-diagonal entries.
Notice that a diagonal preconditioning cannot capture the off-diagonal correlation structure.
The log density is:
\[
    \log p(\skx) \propto -\frac{1}{2}\skx^T \s[k]\Sigma^{-1} \skx
\]

\begin{table}[h]
    \centering
    \caption{Performance comparison on Correlated Gaussian ($d = 50$)}
    \begin{tabular}{lcccccc}
        \hline
        Method      & $\hat{R}$ & ESS           & Acceptance Rate   & Time/chain (s)    & $L$                & $\epsilon$        \\
        \hline
        BayesOpt    & 1.003     & 3186 $\pm$ 31 & 0.756 $\pm$ 0.003 & 0.763 $\pm$ 0.155 & 24.776             & 3.572             \\
        Auto-tuning & 1.003     & 3223 $\pm$ 34 & 0.891 $\pm$ 0.031 & 3.590 $\pm$ 0.781 & 14.142 $\pm$ 0.000 & 2.650 $\pm$ 0.085 \\
        \hline
    \end{tabular}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{../code/plots/traces_Correlated Gaussian.png}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{../code/plots/bayesopt_progress_Correlated Gaussian.png}
\end{figure}






\subsection{Banana Distribution}

The banana distribution, also known as the Rosenbrock or crescent distribution, has a curved shape that can be a significant challenge for samplers.
In $d$ dimensions, the density is:
\[
    p(\skx) \propto \exp \lt( -\sum_{i=1}^{d-1} \lt[ (a - x_i)^2 + b(x_{i+1} - x_i^2)^2 \rt] \rt).
\]
When $d = 2$ with parameters $a = 1$ and $b = 100$, the log density becomes:
\[
    \log p(\skx) \propto  -(1 - x_1)^2 - 100(x_2 - x_1^2)^2
\]

This distribution creates strong nonlinear dependencies between consecutive dimensions.
The high curvature results in a narrow curved ridge with the probability mass.
This is a difficult target density for samplers, and its geometry is a different challenge than either the multimodal or correlated Gaussian targets.

\begin{table}[h]
    \centering
    \caption{Performance comparison on Banana Distribution ($d = 2$)}
    \begin{tabular}{lcccccc}
        \hline
        Method      & $\hat{R}$ & ESS             & Acceptance Rate   & Time/chain (s)     & $L$               & $\epsilon$        \\
        \hline
        BayesOpt    & 1.000     & 10132 $\pm$ 243 & 0.946 $\pm$ 0.003 & 37.839 $\pm$ 0.275 & 39.602            & 0.010             \\
        Auto-tuning & 1.001     & 10182 $\pm$ 460 & 0.885 $\pm$ 0.027 & 9.114 $\pm$ 1.562  & 2.828 $\pm$ 0.000 & 0.020 $\pm$ 0.002 \\
        \hline
    \end{tabular}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{../code/plots/traces_Banana.png}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{../code/plots/bayesopt_progress_Banana.png}
\end{figure}






\subsection{Discussion}

For all three target distributions, both BayesOpt and Auto-tuning hyperparameter tuning methods produced similar sampling performances.
This suggests that for these targets, the $(L, \epsilon)$ hyperparameter space contains regions where hyperparamater configurations perform similarly,
and so these targets do not require precise tuning.

We can examine the EEE, $\hat{R}$, and objective as BayesOpt iteratively explores the hyperparameter space.
For the bimodal Gaussian, as the chains never mixed well, the best hyperparamaters appear to have minimized $\hat{R}$.
For none of the three targets do we see the hyperparameters which maximize the objective function occuring near the end of the chain.
Perhaps if BayesOpt was granted more iterations we would see more optimization rather than exploration.

For each target and each tuning method, we plot the trace of the chain for its first dimension to assess convergence.
The bimodal target has clear poor mixing.
We also show a scatterplot of the first two dimensions.
For the banana, we can see that the BayesOpt tuning allows for much greater distances between consecutive samples.

For the bimodal Gaussian, both methods fail to achieve adequate convergence, with $\hat{R} > 2$.
Neither method found hyperparameters capable of easily mode-switching in the validation chain length of 5000.
The mean ESS values are nearly identical (61023 for BayesOpt versus 61091 for auto-tuning), which are much greater than the chain length of 5000,
and both methods have high acceptance rates above 0.96.
The notable difference lies in the discovered hyperparameters:
BayesOpt selected a much longer trajectory length of $14.901$ paired with a larger step size of $2.242$ compared to those
of Auto-tuning with $L = 1.310 \pm 0.119$ and $\epsilon = 1.191 \pm 0.108$.
Notice that $\lceil 1.310 / 1.191 \rceil = 2$ and so the trajectory simulated is very short.
Here, the standard deviations of $L$ and $\epsilon$ between chains is not negligible,
though it is possible that $\lceil L \epsilon \rceil = n = 2$ holds for all 10 chains.
BayesOpt achieves substantially faster wall-clock time (0.742 seconds versus 2.908 seconds),
likely due to having pre-optimized hyperparameters.


Both methods succesfuly converge for the correlated Gaussian, both with $\hat{R} = 1.003$.
Here again, ESS values are nearly identical (3186 for BayesOpt versus 3223 for auto-tuning).
Again, BayesOpt chooses a longer trajectory and larger step size, $24.776$ versus $14.142$, and $3.572$ versus $2.650$ respectively.
The auto-tuning method achieves higher acceptance rates (0.891 versus 0.756).
BayesOpt performed better in terms of wall-clock time, completing chains in 0.763 seconds compared to 3.590 seconds for auto-tuning.


For the banana distribution, both methods achieve excellent convergence with $\hat{R} \approx 1.000$.
Both methods have nearly identical ESS values (10132 for BayesOpt versus 10182 for auto-tuning).
The hyperparameter differences are extreme.
BayesOpt selected an extremely long trajectory $L = 39.602$ with a very small step size $\epsilon = 0.010$.
These are nearly at the bounds of the hyperparameter search space with $L \in [0.5, 40.0]$ and $\epsilon \in [0.01, 4.0]$.
Auto-tuning chose much shorter trajectories $L = 2.828$ with slightly larger step sizes $\epsilon = 0.020$, both with small variability.
These represent fundamentally different strategies with BayesOpt choosing many small steps along a long trajectory
whereas Auto-tuning chose fewer larger steps along a short trajectory.
And interestingly, BayesOpt with the lower trajectory had higher acceptance rates.
The wall-clock time relationship seen for the bimodal Gaussian and correlated Gaussian reverses for this target,
with auto-tuning completing chains in $9.114 \pm 1.562$ seconds compared to BayesOpt's $37.839 \pm 0.275$ seconds.
This is not surprising as the BayesOpt trajectory requires many more computations than that of auto-tuning.



Interestingly, auto-tuning discovers hyperparameters with low variability across chains,
suggesting this hyperparameter tuning algorithm converges to a local optima.

In our experiments, auto-tuning was slower for the bimodal and correlated Gaussian targets.
For the banana distribution, BayesOpt's extremely long trajectories made it slower.

For computational cost, for each target here, BayesOpt spends 100000 samples upfront but reuses the same hyperparameters for all chains.
Auto-tuning discarded 1000 samples adapting each of the 10 chains of length 5000, discarding 10000 samples total for the validation portion of the analysis.
For large-scale applications with many chains, BayesOpt's amortized cost may be lower.
That said, you could also share hyperparameters found through auto-tuning across chains.


Our approach has several limitations.
We only tune trajectory length and step size, leaving the inverse mass matrix fixed.
We do not consider the Langevin-like version of MAMS, which has an additional partial momentum resampling hyperparameter.
The BayesOpt search uses 20 iterations, which may be insufficient for some targets and hyperparameter search space.
The hyperparamater search space used here allows for the step size to be greater than the trajectory length,
though this did not become a problem, it should be fixed in the future.
Our objective function, lacks rigorous theoretical justification.
It was constructed to that way to avoid high ESS from poor mixing and many rejections.
Here, we have not compared either tuning method to a canonical HMC algorithm,
and so it is possible that the sampler can be outperformed regardless of the tuning method.
Finally, our experiments are limited to three relatively low-dimensional targets with $d \leq 50$.
Performance in higher dimensions remains untested.


\subsection{Conclusion}

We compared the sequential tuning algorithm of RCS to joint optimization via Bayesian optimization.
Our results indicate that the choice of tuning method has minimal impact on sampling performance.
The two methods choose drastically different trajectory lengths and step sizes.
Despite discovering substantially different hyperparameter configurations,
both methods achieve similar effective sample sizes and $\hat{R}$ values across all three targets tested.
This means one can choose a tuning method based on convenience and computational budget.
BayesOpt requires a one-time upfront optimization, auto-tuning requires adaptation every per chain.
Which is preferable depends on which discards fewer samples.



% % Bibliography
% % \clearpage
% % \addcontentsline{toc}{section}{Bibliography} % Adds "Bibliography" to the table of contents
% % \bibliographystyle{unsrt} % Other options are plain, unsrt, apalike
% % \bibliography{references}   % Looks for references.bib

% References
\clearpage
\addcontentsline{toc}{section}{References}
\bibliographystyle{unsrt}
\bibliography{references}

\end{document}







